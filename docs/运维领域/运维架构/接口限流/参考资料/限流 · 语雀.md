# 限流

keywords: limiter、限流器



对并发或者一个时间窗口内的请求限速来保护系统。

达到限制条件后：

- 拒绝服务（定位到错误页）
- 排队或等待（秒杀、评论、下单）
- 降级（返回兜底或默认数据）

常见限流方法：

- 限制总并发数（数据库连接池、线程池）
- 限制瞬时并发量（Nginx 的 limit_conn）
- 限制时间窗口内的平均速率（Guava 的 RateLimiter、Nginx 的 limit_req）
- 限制远程接口（总数或不同调用方的）调用速率
- 限制 MQ 消费速率
- 其他：网络连接数、网络流量、CPU 或内存负载

## 限流算法

- 窗口法适用于对时间敏感的否决式限流，比如微服务
- 令牌、漏桶法适合于 job 类阻塞限流

### 固定时间窗口

- 按固定的时间窗口，比如每秒
- 实现简单
- 缺点

- - 限流算法粗略
  - 无法应对窗口临界点间的突发流量

### 滑动时间窗口

- 窗口滑动，保证任意时间窗口内都不会超过最大允许的限流值
- 可以部分解决临界点突发流量问题
- 每个请求过来都形成一个窗口，空间复杂度高，内存消耗大
- 但是粒度是固定的，可以用多粒度限流方案叠加的方式来改进（1s 100 次 + 100ms 20 次）

### 令牌桶

- 桶内可以存放固定容量的 token
- 固定速率往桶内放 token，桶满时不再添加
- 数据包到时删除 n 个 token // 可能按某个单位来消耗 token？？？
- token 不够用时该数据包被限流（丢弃或等待）// 数据包 == 请求？？？
- 实现没那么难，可以在取的时候再计算并放入 token，未必用专门的线程来定时完成

效果

- 允许一定程度的突发流量

### 漏桶算法

- 可以看成是令牌桶的改进版
- 桶固定容量
- 固定速率流出，桶空时不流出
- 桶满再流入就丢弃

效果

- 主要可以平滑流入速率 // 从桶内流出速率固定

### 计数器

- 主要限制总并发数
- 数据库连接池大小、线程池大小、秒杀并发数
- 粗暴的总数量限流，而不出平均速率限流

## 应用级限流

### 限流总并发/连接/请求数

系统总用极限的并发/请求数，TPS/QPS 阈值

tomcat 的配置：

- maxThreads，处理请求的最大线程数，长时间打满响应大概是慢的
- maxConnections，瞬时最大连接数，超出排队
- acceptCount，最大排队数，超出丢弃

其他：

- MySQL max_connections
- Redis tcp-backlog

### 限流总资源数

- 整体资源有限（数据库连接、线程），多个系统在用
- 按池分配一个最大数量

### 限流某个接口的总并发/请求数

- 接口粒度，设置自己的最大并发/请求数
- 粗暴的计数器限流

### 限制某个接口的时间窗请求数

- 限制每秒/每分钟/每天的请求数
- 时间段起始时间做 key 统计请求数，结束时间做过期时间，达到限制就处理

### 平滑限制某个接口的请求数

- 上面的不能很好的应对突发请求
- 可以用令牌桶或者漏桶算法实现

## 分布式限流

- 算法可以分布式部署在多台机器上面，多台机器协同提供限流功能，可以对同一接口或者服务做限流
- 相较于单机的限流算法，最大的区别就是接口请求计数器需要中心化存储，可以用 Redis 中心计数器
- 关键是要将限流服务做成原子化，比如用 Redis + lua 或者 Nginx + lua

引入 Redis 中心计数器之后要解决的问题

- 数据一致性

- - 读数据、判断是否限流、写数据
  - 多线程时用线程锁或者原子化操作解决
  - 引入分布式锁
  - 或者简单一点用 Redis 的单线程模式 + lua 脚本实现

- 超时

- - 访问 Redis 需要设置合理的超时时间
  - 超时就认为限流失败

- 性能

- - 分布式限流算法瓶颈在中心计数器 Redis
  - 性能一般要远低于单机的限流算法
  - 如果限流算法的最大 TPS 已经低于了服务的最大 TPS 就有问题了

其他相关

- 将一致性哈希将分布式限流进行分片
- 并发量太大时降级为应用级限流

单机限流还是分布式限流

- 单机限流

- - 初衷防止流量压垮服务器
  - 适合针对并发做限制

- 分布式限流

- - 适合做细粒度限流或访问配额
  - 不同调用方执行不同的限流规则

微服务分布式限流部署架构

- 在接入层（api-gateway）集成限流功能

- - 有 api-gateway 的时候最合适
  - 单实例部署 api-gateway 用单机限流算法
  - 多实例部署 api-gateway 用分布式限流算法

- 限流功能封装为 RPC 服务

- - 微服务收到请求先调用限流 RPC 服务
  - 复杂度高，部署成本高
  - 调用 RPC 服务开销大

- 限流功能集成在微服务系统内

- - 不需要再独立部署限流服务
  - 可以尽量把限流算法和业务代码解耦

## 限流熔断策略

- 不同服务用不同的策略
- 熔断策略：当接口达到限流上限之后，如何来处理接口请求的问题

- - 否决式限流

- - - 直接拒绝请求，比如返回 HTTP code 429
    - 响应时间敏感

- - 阻塞式限流

- - - 超过最大允许访问频率之后就排队请求
    - job 类

- - 记录日志，发送告警

- - - 限流刚上线的时候不真的限流，只查看效果用

- - 服务降级

## 设置合理的限流规则

- 时间粒度

- - 太大起不到效过，容易漏放
  - 太小容易误杀

- 接口粒度

- - 集群整体的访问频率
  - 每个实例接口调用频率
  - 某服务的某个接口的访问频率
  - 某个调用方对某个服务的调用频率
  - 某个调用方对某个服务的某个接口的访问频率

- 最大限流值

- - 结合性能压测数据、业务预期流量、线上监控数据来综合设置，最大允许访问频率不大于压测 TPS，不小于业务预期流量，并且参考线上监控数据

## 限流功能是否正确有效

- 导流的方式将流量集中到一小组机器上做真实场景的测试
- 模拟流量或者线上流量回放等手段来测试
- 至少需要记录每个请求的如下信息：对应接口，请求时间点，限流结果 (通过还是熔断)

## 接入层限流

nginx 自带的两个模块

- 连接数限流模块 ngx_http_limit_conn_module
- 漏桶算法实现的请求限流模块 ngx_http_limit_req_module

## 节流

- 特定时间窗口内重复的事件最后只处理一次，或者限制连续相同事件的最小执行间隔，防止重复执行
- throttleFirst、throttleLast、throttleWithTimeout
- 很多客户端应用响应的时候会用到
- // 也可以用来防止用户重复操作，比如因为网络不好重复创建了信息？？？

## 参考

- 《亿级流量网站架构核心技术》
- [微服务接口限流的设计与思考（附GitHub框架源码）](https://www.infoq.cn/article/microservice-interface-rate-limit)
- [Rate limiting - Wikipedia](https://en.wikipedia.org/wiki/Rate_limiting)